{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from textblob import Word\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download as nltk_download\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets.twenty_newsgroups import fetch_20newsgroups\n",
    "\"\"\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words=stopwords.words('english')\n",
    "\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IEA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albania', 'Algeria', 'Australia', 'Austria', 'Belgium', 'Bosnia and Herzegovina', 'Brazil', 'Canada', 'China', 'Croatia', 'Czech Republic', 'Denmark', 'Estonia', 'European Union', 'Finland', 'France', 'Germany', 'Ghana', 'Greece', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Ireland', 'Israel', 'Italy', 'Japan', 'Korea', 'Latvia', 'Luxembourg', 'Malaysia', 'Mauritius', 'Mexico', 'Mongolia', 'Montenegro', 'Netherlands', 'New Zealand', 'Norway', 'Poland', 'Portugal', 'Romania', 'Russia', 'Slovak Republic', 'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Turkey', 'United Kingdom', 'United States']\n"
     ]
    }
   ],
   "source": [
    "#get all countries with entiries in the IEA database\n",
    "get_countries = \"https://www.iea.org/policiesandmeasures/climatechange/\"\n",
    "g_c = get(get_countries)\n",
    "\n",
    "soup_c = BeautifulSoup(g_c.text, 'html.parser')\n",
    "c_list = soup_c.find(\"ul\", class_ =\"listexpander\")\n",
    "c_loop = c_list.find_all(\"label\")\n",
    "\n",
    "country_store = []\n",
    "for c in c_loop:\n",
    "    country_store.append(c.text)\n",
    "    \n",
    "full_list = country_store[4:]\n",
    "print(full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "#get each countries directory of database entries for climate policies and measure, renewable energy, \n",
    "#and energy efficiency\n",
    "\n",
    "def get_countries(link_store, url):\n",
    "    for country in full_list:\n",
    "        if \" \" in country:\n",
    "            amend = country.replace(\" \", \"%20\")\n",
    "            policy_link = url + amend \n",
    "            link_store.append(policy_link)\n",
    "        else:\n",
    "            policy_link = url + country\n",
    "            link_store.append(policy_link)\n",
    "        \n",
    "#for climate policies and measure database\n",
    "policy_link_store = []\n",
    "get_countries(policy_link_store, \"https://www.iea.org/policiesandmeasures/climatechange/?country=\")\n",
    "print(len(policy_link_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "#for renewable energy\n",
    "renewables_store = []\n",
    "get_countries(renewables_store, \"https://www.iea.org/policiesandmeasures/renewableenergy/?country=\")\n",
    "print(len(renewables_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "#energy efficiency\n",
    "efficiency_store = []\n",
    "get_countries(efficiency_store, \"https://www.iea.org/policiesandmeasures/energyefficiency/?country=\")\n",
    "print(len(efficiency_store))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get individual links for each entry in db\n",
    "\n",
    "def store_pages(store, ptype):\n",
    "    for p in ptype:\n",
    "        g_p = session.get(p)\n",
    "        soup_p = BeautifulSoup(g_p.text, 'html.parser')\n",
    "        entries = soup_p.find_all(\"tr\")[1:]\n",
    "        for entry in entries:\n",
    "            ext = entry.find(\"a\", href = True)\n",
    "            link = \"https://www.iea.org/\" + ext._attr_value_as_string(\"href\")\n",
    "            store.append(link)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2790\n"
     ]
    }
   ],
   "source": [
    "#get individual links for each policy and measure page for each country          \n",
    "page_link_store = []\n",
    "store_pages(page_link_store, policy_link_store) \n",
    "print(len(page_link_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get individual links for each renewable energy policy for each country \n",
    "renewpage_link_store = []\n",
    "store_pages(renewpage_link_store,renewables_store)\n",
    "print(len(renewpage_link_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get individual links for each energy efficiency policy for each country \n",
    "eff_page_link_store = []\n",
    "store_pages(eff_page_link_store, efficiency_store)\n",
    "print(len(eff_page_link_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape each climate policy webpage in db\n",
    "full_set = []\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "        futures = [\n",
    "            loop.run_in_executor(\n",
    "                executor, \n",
    "                session.get, \n",
    "                link\n",
    "            )\n",
    "            for link in page_link_store\n",
    "        ]\n",
    "        \n",
    "        for response in await asyncio.gather(*futures):\n",
    "            soup_e = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            table = soup_e.find(\"tbody\").find_all(\"td\")\n",
    "\n",
    "            entry = dict()\n",
    "            for i in range(len(table)):\n",
    "\n",
    "                \n",
    "                if \"Policy Type\" in table[i].text:\n",
    "                    entry[table[i].text.lower()] = table[i+1].text.lower()\n",
    "\n",
    "                elif \"Description\" in table[i].text:\n",
    "                    entry[table[i].text.lower()] = table[i+1].text.lower()\n",
    "\n",
    "            full_set.append(entry)\n",
    "\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape each renewable energy policy webpage in db\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "        futures = [\n",
    "            loop.run_in_executor(\n",
    "                executor, \n",
    "                session.get, \n",
    "                link\n",
    "            )\n",
    "            for link in renewpage_link_store\n",
    "        ]\n",
    "        \n",
    "        for response in await asyncio.gather(*futures):\n",
    "            soup_e = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            table = soup_e.find(\"tbody\").find_all(\"td\")\n",
    "\n",
    "            entry = dict()\n",
    "            for i in range(len(table)):\n",
    "\n",
    "    \n",
    "                if \"Policy Type\" in table[i].text:\n",
    "                    entry[table[i].text.lower()] = table[i+1].text.lower()\n",
    "\n",
    "                elif \"Description\" in table[i].text:\n",
    "                    entry[table[i].text.lower()] = table[i+1].text.lower()\n",
    "\n",
    "            full_set.append(entry)\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape each energy efficiency policy webpage in db\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "        futures = [\n",
    "            loop.run_in_executor(\n",
    "                executor, \n",
    "                session.get, \n",
    "                link\n",
    "            )\n",
    "            for link in eff_page_link_store\n",
    "        ]\n",
    "        \n",
    "        for response in await asyncio.gather(*futures):\n",
    "            soup_e = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            table = soup_e.find(\"tbody\").find_all(\"td\")\n",
    "\n",
    "            entry = dict()\n",
    "            for i in range(len(table)):\n",
    "\n",
    "     \n",
    "                if \"Policy Type\" in table[i].text:\n",
    "                    entry[table[i].text.lower()] = table[i+1].text.lower()\n",
    "\n",
    "                elif \"Description\" in table[i].text:\n",
    "                    entry[table[i].text.lower()] = table[i+1].text.lower()\n",
    "\n",
    "            full_set.append(entry)\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('climate change policy db:', len(page_link_store))\n",
    "print('renewable energy policy db:', len(renewpage_link_store))\n",
    "print('energy efficiency db:', len(eff_page_link_store))\n",
    "\n",
    "print('total:', len(full_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iea_separate.json', 'w') as outfile:\n",
    "    json.dump(full_set, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = pd.read_json('iea_separate.json', 'column')\n",
    "fixed = load.drop(load.columns[2:4], axis=1)\n",
    "fixed['label'] = 1\n",
    "fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EU Climate Change Mitigation Policies and Measures Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323\n",
      "http://cdr.eionet.europa.eu/Converters/run_conversion?file=/ec/mmr/art04-13-14_lcds_pams_projections/colvzkuna/envvzkvxq/CZ_MMR_PAM__20150626.xml&conv=524&source=remote#pam21\n",
      "1323\n",
      "http://cdr.eionet.europa.eu/Converters/run_conversion?file=/ec/mmr/art04-13-14_lcds_pams_projections/colvzkuna/envvzkvxq/CZ_MMR_PAM__20150626.xml&conv=524&source=remote#pam21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/silas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1323, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load data\n",
    "eu_db = pd.read_csv('../Data/EU_climate_change_mitigation_policies_and_measures.csv')\n",
    "\n",
    "eu_db.head()\n",
    "\n",
    "links = eu_db['ReportID:text'].tolist()\n",
    "print(len(links))\n",
    "print(links[0])\n",
    "\n",
    "description = eu_db[['Description:text']]\n",
    "description['label'] = 1\n",
    "description.head()\n",
    "\n",
    "eu_db.head()\n",
    "\n",
    "links = eu_db['ReportID:text'].tolist()\n",
    "print(len(links))\n",
    "print(links[0])\n",
    "\n",
    "description = eu_db[['Description:text']]\n",
    "description['label'] = 1\n",
    "description.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
